{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a360da",
   "metadata": {},
   "source": [
    "## Neste código construiremos 3 redes neurais para aproximar derivadas.\n",
    "## Nos meus testes os resultados foram positivos, mas não posso garantir a consistência dos resultados devido a aleatoriedade do conjunto de dados criado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11df3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "float_pres='float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f185a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando conjunto de dados\n",
    "\n",
    "data_x_list=[]\n",
    "data_y_list=[]\n",
    "pi=np.pi\n",
    "\n",
    "for i in range(5000):\n",
    "    Δx = 0.01                                 # Distância espacial dos pontos na malha utilizada\n",
    "    x = tf.range(-2, 2, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "    \n",
    "    # Gerando uma condição inicial aleatória\n",
    "    #------------------------------------------------------------------------------------------------------------------\n",
    "#     k1 = tf.random.uniform([1], 0, 20, dtype='int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "#     k1 = tf.cast(k1, dtype=float_pres)                  # Mudando o tipo do tensor\n",
    "#     k2 = tf.random.uniform([1], 0, 20, dtype='int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "#     k2 = tf.cast(k2, dtype=float_pres)                  # Mudando o tipo do tensor\n",
    "#     a  = tf.random.uniform([1], 0, 1, dtype=float_pres) # Amostrando um peso aleatória para ponderar as funções seno\n",
    "#     b  = tf.random.uniform([1], 0, 2, dtype=float_pres) # Amostrando um modificador de amplitude aleatório\n",
    "    #------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Valor da função\n",
    "#     u1 =     a * tf.expand_dims(tf.math.sin(k1*pi*x), axis=0) # Gerando pontos de acordo com a primeira função seno\n",
    "#     u2 = (1-a) * tf.expand_dims(tf.math.sin(k2*pi*x), axis=0) # Gerando pontos de acordo com a segunda função seno\n",
    "    \n",
    "    # Valor da derivada\n",
    "#     du1= a*k1*pi*tf.expand_dims(tf.math.cos(k1*pi*x), axis=0)\n",
    "#     du2= (1-a)*k2*pi*tf.expand_dims(tf.math.cos(k2*pi*x), axis=0)\n",
    "    \n",
    "#     u = b*(u1+u2) \n",
    "#     du= b*(du1+du2)\n",
    "    \n",
    "#     a = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "#     b = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    \n",
    "#     u  = tf.expand_dims(a*x + b, axis=0)\n",
    "#     du = tf.expand_dims(0*x + a, axis=0)\n",
    "    \n",
    "#     data_x_list.append(u)\n",
    "#     data_y_list.append(du)\n",
    "    \n",
    "    a = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    b = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    c = tf.random.uniform([1], -1, 1, dtype=float_pres)\n",
    "    \n",
    "    u  = tf.expand_dims(  a*x**2 + b*x + c, axis=0)\n",
    "    du = tf.expand_dims(2*a*x    + b      , axis=0)\n",
    "    \n",
    "    data_x_list.append(u)\n",
    "    data_y_list.append(du)\n",
    "    \n",
    "    a = tf.random.uniform([1], -2, 2, dtype=float_pres)\n",
    "    b = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    c = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    d = tf.random.uniform([1], -3, 3, dtype=float_pres)\n",
    "    \n",
    "    u  = tf.expand_dims(  a*x**3 +   b*x**2 + c*x + d, axis=0)\n",
    "    du = tf.expand_dims(3*a*x**2 + 2*b*x    + c      , axis=0)\n",
    "    \n",
    "    data_x_list.append(u)\n",
    "    data_y_list.append(du)\n",
    "\n",
    "data_x = tf.concat(data_x_list,axis=0)\n",
    "data_y = tf.concat(data_y_list,axis=0)\n",
    "\n",
    "train_x = data_x[:40000]\n",
    "train_y = data_y[:40000]\n",
    "test_x  = data_x[-40000:]\n",
    "test_y  = data_y[-40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4a3271af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo sequencial\n",
    "model_foward=tf.keras.models.Sequential()\n",
    "\n",
    "# Adicionando camadas\n",
    "model_foward.add(tf.keras.layers.Reshape([400,1])) # A camada de convolução exige uma dimensão extra para a \"cor\" da imagem,\n",
    "                                            # por isso o reshape para transformar o tensor de tamanho n x 400 em um tensor de tamanho n x 400 x 1\n",
    "model_foward.add(tf.keras.layers.Conv1D(filters=1,activation='linear', kernel_size=4, use_bias=False,dtype=float_pres)) # Camada de convolução com ativação linear, após a convolução, a dimensão do vetor será n x 399.\n",
    "                                                                                                       # Lembrando que, se temos um input com dimensão n x s x r e uma convolução com filtro a x b (a é o tamanho do kernel e b é a quantidade de filtros) \n",
    "                                                                                                       # Então o output da convolução será: n x (s-a+1) x b\n",
    "                                                                                                       # Dada a natureza do problema, sabemos que não é necessário um bias (use_bias=False), então removemos ele para evitar overfitting.\n",
    "model_foward.add(tf.keras.layers.Flatten()) # Esta camada remove a dimensão extra, transformando um tensor de tamanho n x 399 x 1 em um tensor de tamanho n x 399\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=10**-1, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model_foward.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "461dac82-3fb5-49a1-b338-a318ccbf6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "class ClearOutput(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, *logs):\n",
    "        clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "236bac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0568\n",
      "Test loss: 0.056810710579156876\n"
     ]
    }
   ],
   "source": [
    "history = model_foward.fit(train_x, train_y[:,1:-2], # Como estamos calculando a derivada \"pra frente\", devemos remover a última derivada\n",
    "                           batch_size=512,\n",
    "                           epochs=30,\n",
    "                           callbacks = [ClearOutput()],\n",
    "                           validation_split=0.2)\n",
    "test_scores = model_foward.evaluate(test_x, test_y[:,1:-2], verbose=1)\n",
    "print('Test loss:', test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d7dca7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 1), dtype=float64, numpy=\n",
       "array([[[-0.29447868]],\n",
       "\n",
       "       [[-0.11034934]],\n",
       "\n",
       "       [[ 0.10817446]],\n",
       "\n",
       "       [[ 0.29608895]]])>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pegando os pesos da segunda camada (a de convolução) da rede e multiplicando por Δx para ver se o valor está correto (o ideal seria -1 e 1).\n",
    "model_foward.layers[1].weights[0]*Δx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "054ac2f8-c634-4d24-ba66-d7a2fbefba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 15.2933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.29328441619873"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = 10\n",
    "\n",
    "u  =       tf.expand_dims(tf.math.sin(k1*pi*x), axis=0) # Gerando pontos de acordo com a primeira função seno\n",
    "du = k1*pi*tf.expand_dims(tf.math.cos(k1*pi*x), axis=0) # Gerando pontos de acordo com a primeira função coseno\n",
    "\n",
    "# a = model_foward.layers[1].weights[0][0]*Δx\n",
    "# b = model_foward.layers[1].weights[0][1]*Δx\n",
    "# c = model_foward.layers[1].weights[0][2]*Δx\n",
    "# d = model_foward.layers[1].weights[0][3]*Δx\n",
    "\n",
    "model_foward.evaluate(u, du[:,1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1560cdaf-117d-4350-9d27-8f21cbde90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes Analíticos:  tf.Tensor(0.001083501900011149, shape=(), dtype=float64)\n",
      "Coeficientes Apreendidos: tf.Tensor(0.05681070189231972, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes exatos\n",
    "a = -3/10\n",
    "b = -1/10\n",
    "c =  1/10\n",
    "d =  3/10\n",
    "\n",
    "print(\"Coeficientes Analíticos: \",tf.math.reduce_mean(((a*test_x[:,:-3]+b*test_x[:,1:-2]+c*test_x[:,2:-1]+d*test_x[:,3:])/Δx-test_y[:,1:-2])**2))\n",
    "\n",
    "# Outros coeficientes\n",
    "a = model_foward.layers[1].weights[0][0]*Δx\n",
    "b = model_foward.layers[1].weights[0][1]*Δx\n",
    "c = model_foward.layers[1].weights[0][2]*Δx\n",
    "d = model_foward.layers[1].weights[0][3]*Δx\n",
    "\n",
    "print(\"Coeficientes Apreendidos:\",tf.math.reduce_mean(((a*test_x[:,:-3]+b*test_x[:,1:-2]+c*test_x[:,2:-1]+d*test_x[:,3:])/Δx-test_y[:,1:-2])**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo sequencial\n",
    "model_backward=tf.keras.models.Sequential()\n",
    "\n",
    "# Adicionando camadas\n",
    "model_backward.add(tf.keras.layers.Reshape([400,1])) # A camada de convolução exige uma dimensão extra para a \"cor\" da imagem,\n",
    "                                            # por isso o reshape para transformar o tensor de tamanho n x 400 em um tensor de tamanho n x 400 x 1\n",
    "model_backward.add(tf.keras.layers.Conv1D(filters=1,activation='linear', kernel_size=2, use_bias=False)) # Camada de convolução com ativação linear, após a convolução, a dimensão do vetor será n x 399.\n",
    "                                                                                                         # Lembrando que, se temos um input com dimensão n x s x r e uma convolução com filtro a x b (a é o tamanho do kernel e b é a quantidade de filtros) \n",
    "                                                                                                         # Então o output da convolução será: n x (s-a+1) x b\n",
    "model_backward.add(tf.keras.layers.Flatten()) # Esta camada remove a dimensão extra, transformando um tensor de tamanho n x 399 x 1 em um tensor de tamanho n x 399\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=10**-1, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model_backward.compile(loss='mean_squared_error',optimizer=optimizer,metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7be71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_backward.fit(train_x, train_y[:,1:], # Como estamos calculando a derivada \"pra trás\", devemos remover a primeira derivada\n",
    "                    batch_size=512,\n",
    "                    epochs=30,\n",
    "                    validation_split=0.2)\n",
    "test_scores = model_backward.evaluate(test_x, test_y[:,1:], verbose=1)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c891f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os pesos da segunda camada (a de convolução) da rede e multiplicando por Δx para ver se o valor está correto (o ideal seria -1 e 1).\n",
    "model_backward.layers[1].weights[0]*Δx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d159c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo sequencial\n",
    "model_middle=tf.keras.models.Sequential()\n",
    "\n",
    "# Adicionando camadas\n",
    "model_middle.add(tf.keras.layers.Reshape([400,1])) # A camada de convolução exige uma dimensão extra para a \"cor\" da imagem,\n",
    "                                            # por isso o reshape para transformar o tensor de tamanho n x 400 em um tensor de tamanho n x 400 x 1\n",
    "# Observe que, para a derivada centrada, o kernel_size deve ser 3.\n",
    "model_middle.add(tf.keras.layers.Conv1D(filters=1,activation='linear', kernel_size=3, use_bias=False)) # Camada de convolução com ativação linear, após a convolução, a dimensão do vetor será n x 398.\n",
    "                                                                                                       # Lembrando que, se temos um input com dimensão n x s x r e uma convolução com filtro a x b (a é o tamanho do kernel e b é a quantidade de filtros) \n",
    "                                                                                                       # Então o output da convolução será: n x (s-a+1) x b\n",
    "model_middle.add(tf.keras.layers.Flatten()) # Esta camada remove a dimensão extra, transformando um tensor de tamanho n x 399 x 1 em um tensor de tamanho n x 399\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=10**-1, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model_middle.compile(loss='mean_squared_error',optimizer=optimizer,metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_middle.fit(train_x, train_y[:,1:-1], # Como estamos calculando a derivada centrada, devemos remover a primeira e a última derivada\n",
    "                    batch_size=512,\n",
    "                    epochs=30,\n",
    "                    validation_split=0.2)\n",
    "test_scores = model_middle.evaluate(test_x, test_y[:,1:-1], verbose=1)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187640a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os pesos da segunda camada (a de convolução) da rede e multiplicando por Δx para ver se o valor está correto (o ideal seria -1 e 1).\n",
    "model_middle.layers[1].weights[0]*Δx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
