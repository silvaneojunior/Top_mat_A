{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e604fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos que serão utilizados\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Configurando o acesso do tensorflow aos processadores do computador\n",
    "# no caso, está sendo selecionada a primeira placa de vídeo listada\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # Listando as placas de vídeo\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)    # Selecionando a primeira GPU e configurando\n",
    "\n",
    "# Importando os módulos contendo as funções criadas no projeto\n",
    "\n",
    "from aux_func_V2 import *\n",
    "import aux_func_numpy as debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c44af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que define a taxa de aprendizagem para diferentes\n",
    "# iterações de treino, a ideia é começar com uma taxa grande e \n",
    "# diminuir ao longo do treino para \"refinar\" a aprendizagem da rede\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return 10**-2\n",
    "    elif epoch<2:\n",
    "        return 10**-3\n",
    "    else:\n",
    "        return 10**-4\n",
    "    \n",
    "# Passando para o keras a função scheduler\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b28a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.asarray([[0.5],[-2],[3/2],[0],[0]])\n",
    "b = np.asarray([[1],[-2],[1],[0],[0]])\n",
    "c = 13/12\n",
    "\n",
    "A0 = np.dot(a,a.T)+c*np.dot(b,b.T) # Primiera matriz A\n",
    "\n",
    "a = np.asarray([[0],[-0.5],[0],[0.5],[0]])\n",
    "b = np.asarray([[0],[1],[-2],[1],[0]])\n",
    "c = 13/12\n",
    "\n",
    "A1 = np.dot(a,a.T)+c*np.dot(b,b.T) # Segunda matriz A\n",
    "\n",
    "a = np.asarray([[0],[0],[-3/2],[2],[-1/2]])\n",
    "b = np.asarray([[0],[0],[1],[-2],[1]])\n",
    "c = 13/12\n",
    "\n",
    "A2 = np.dot(a,a.T)+c*np.dot(b,b.T) # Terceira matriz A\n",
    "\n",
    "# Empilhando as matrizes A em um único tensor\n",
    "A = tf.cast(tf.stack([A0,A1,A2], axis=0), dtype=float_pres) \n",
    "A = tf.expand_dims(A, axis=1)\n",
    "\n",
    "B = tf.constant([[1,0,0],[0,6,0],[0,0,3]], dtype=float_pres)/10                # Matriz B\n",
    "C = tf.constant([[2,-7,11,0,0],[0,-1,5,2,0],[0,0,2,5,-1]], dtype=float_pres)/6 # Matriz C\n",
    "C = tf.transpose(C)\n",
    "\n",
    "stack_op=np.asarray([[[1]],[[1]],[[1]]])\n",
    "\n",
    "ɛ = 10.0**(-40)\n",
    "\n",
    "class Burguers_layer(keras.layers.Layer):\n",
    "    \"\"\"Criando uma camada de rede neural cuja superclasse é a camada\n",
    "    do keras para integrar o algoritmo do WENO com a rede neural\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Construtor da classe\n",
    "        --------------------------------------------------------------------------------------\n",
    "        t_final      (float): tamanho máximo da variação temporal\n",
    "        Δx           (float): distância espacial dos pontos na malha utilizada\n",
    "        CFL          (float): constante utilizada para determinar o tamanho da malha temporal\n",
    "        fronteira (function): função que determina o comportamento do algoritmo na fronteira\n",
    "        --------------------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        super(Burguers_layer, self).__init__(dtype='float64') # Chamando o inicializador da superclasse\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Função para compor as camadas que constituem essa camada da rede neural\n",
    "        ------------------------------------------------------------------------\n",
    "        input_shape : não é utilizado por essa função, mas é um argumento obrigatório para camadas do Keras.\n",
    "        ------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        wei_reg = tf.keras.regularizers.L2(0*10**-3)                                                                        # Regularização dos pesos da rede \n",
    "        self.layers.append(tf.keras.layers.ZeroPadding1D(padding=2))                                                        # Camada de padding de zeros em 1 dimensão\n",
    "        self.layers.append(keras.layers.Conv1D(5, 5, activation='elu',     dtype=data_x.dtype, kernel_regularizer=wei_reg)) # Camada de convolução em 1 dimensão\n",
    "        self.layers.append(tf.keras.layers.ZeroPadding1D(padding=2))                                                        # Camada de padding de zeros em 1 dimensão\n",
    "        self.layers.append(keras.layers.Conv1D(3, 5, activation='elu',     dtype=data_x.dtype, kernel_regularizer=wei_reg)) # Camada de convolução em 1 dimensão\n",
    "        self.layers.append(keras.layers.Conv1D(1, 1, activation='sigmoid', dtype=data_x.dtype, kernel_regularizer=wei_reg)) # Camada de convolução em 1 dimensão\n",
    "        \n",
    "    def network_graph(self, x):\n",
    "        \"\"\"\n",
    "        Função utilizado para executar sucessivamente as camadas dessa camada \n",
    "        da rede neural, passando o input de uma para a próxima\n",
    "        ----------------------------------------------------------------------\n",
    "        x (tensor): valor de entrada da rede\n",
    "        ----------------------------------------------------------------------\n",
    "        y (tensor): valor de saída da rede\n",
    "        ----------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        y = x # Valor de entrada\n",
    "        \n",
    "        # Percorrendo as camadas\n",
    "        for layer in self.layers:\n",
    "            \n",
    "            # Atualizando o valor de entrada para a próxima camada\n",
    "            y = layer(y) \n",
    "            \n",
    "        return y\n",
    "        \n",
    "    def call(self, inpt, mask=None):\n",
    "        u0=inpt[:,:-1]\n",
    "        u1=inpt[:,1:]\n",
    "        \n",
    "        u_diff=tf.stack([inpt[:,2:]-inpt[:,:-2], inpt[:,2:]-2*inpt[:,1:-1]+inpt[:,:-2]], axis=2)\n",
    "        beta_weigth=self.network_graph(u_diff)\n",
    "        beta_weigth0=beta_weigth[:,:-1,0]\n",
    "        beta_weigth1=beta_weigth[:,1:,0]\n",
    "\n",
    "        # Calcula os indicadores de suavidade locais\n",
    "        u = stack_op*u0\n",
    "\n",
    "        β = tf.math.reduce_sum(u * (u @ A[:,0]), axis=-1)\n",
    "        β = tf.transpose(β)\n",
    "        β = β*(beta_weigth0+0.01)\n",
    "\n",
    "        # Calcula o indicador de suavidade global\n",
    "        τ = tf.abs(β[:,0:1] - β[:,2:3])\n",
    "\n",
    "        # Calcula os pesos do WENO-Z\n",
    "        α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "        soma = tf.math.reduce_sum(α, axis=-1, keepdims=True)\n",
    "        ω    = α / soma\n",
    "\n",
    "        # Calcula os fhat em cada subestêncil\n",
    "        fhat = u0 @ C\n",
    "\n",
    "        # Calcula o fhat do estêncil todo\n",
    "        fhat = ω * fhat\n",
    "        fhat0 = tf.math.reduce_sum(fhat, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calcula os indicadores de suavidade locais\n",
    "        u = stack_op*u1\n",
    "\n",
    "        β = tf.math.reduce_sum(u * (u @ A[:,0]), axis=-1)\n",
    "        β = tf.transpose(β)\n",
    "        β = β*(beta_weigth1+0.01)\n",
    "\n",
    "        # Calcula o indicador de suavidade global\n",
    "        τ = tf.abs(β[:,0:1] - β[:,2:3])\n",
    "\n",
    "        # Calcula os pesos do WENO-Z\n",
    "        α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "        soma = tf.math.reduce_sum(α, axis=-1, keepdims=True)\n",
    "        ω    = α / soma\n",
    "\n",
    "        # Calcula os fhat em cada subestêncil\n",
    "        fhat = u1 @ C\n",
    "\n",
    "        # Calcula o fhat do estêncil todo\n",
    "        fhat = ω * fhat\n",
    "        fhat1 = tf.math.reduce_sum(fhat, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        fhat = (fhat1-fhat0)/Δx\n",
    "        return fhat\n",
    "\n",
    "    def predict(self, inputs, mask=None):\n",
    "        \"\"\"Função que faz previsão a partir de um input\"\"\"\n",
    "        return self(inputs, mask=None) # Chamando o função call (self.predict(inputs, mask) = self.call(inpt, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97eb571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WENO_Z_ref(inpt):\n",
    "    u0=inpt[:,:-1]\n",
    "    u1=inpt[:,1:]\n",
    "\n",
    "    # Calcula os indicadores de suavidade locais\n",
    "    u = stack_op*u0\n",
    "\n",
    "    β = np.sum(u * (u @ A[:,0]), axis=-1)\n",
    "    β = np.transpose(β)\n",
    "\n",
    "    # Calcula o indicador de suavidade global\n",
    "    τ = np.abs(β[:,0:1] - β[:,2:3])\n",
    "\n",
    "    # Calcula os pesos do WENO-Z\n",
    "    α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "    soma = np.sum(α, axis=-1, keepdims=True)\n",
    "    ω    = α / soma\n",
    "\n",
    "    # Calcula os fhat em cada subestêncil\n",
    "    fhat = u0 @ C\n",
    "\n",
    "    # Calcula o fhat do estêncil todo\n",
    "    fhat = ω * fhat\n",
    "    fhat0 = np.sum(fhat, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calcula os indicadores de suavidade locais\n",
    "    u = stack_op*u1\n",
    "\n",
    "    β = np.sum(u * (u @ A[:,0]), axis=-1)\n",
    "    β = np.transpose(β)\n",
    "\n",
    "    # Calcula o indicador de suavidade global\n",
    "    τ = np.abs(β[:,0:1] - β[:,2:3])\n",
    "\n",
    "    # Calcula os pesos do WENO-Z\n",
    "    α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "    soma = np.sum(α, axis=-1, keepdims=True)\n",
    "    ω    = α / soma\n",
    "\n",
    "    # Calcula os fhat em cada subestêncil\n",
    "    fhat = u1 @ C\n",
    "\n",
    "    # Calcula o fhat do estêncil todo\n",
    "    fhat = ω * fhat\n",
    "    fhat1 = np.sum(fhat, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fhat = (fhat1-fhat0)/Δx\n",
    "    return fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=8413651)\n",
    "n=int(100000)\n",
    "k=5\n",
    "x_rep=20\n",
    "pesos=np.random.uniform(size=[n,k],low=-10,high=10)\n",
    "ordem=np.floor(np.random.uniform(size=[n,1],low=0,high=k))+np.asarray([range(k)])\n",
    "pesos=(1-np.sum(tf.one_hot(ordem,k),axis=1))*pesos\n",
    "\n",
    "operador_derivada=np.eye(k,k=-1)@np.diag(range(1,k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998403b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.expand_dims(np.linspace(-1,1,6*x_rep),axis=0)**np.expand_dims(np.arange(k),axis=1)\n",
    "Δx=x[1,1]-x[1,0]\n",
    "x_ref=(np.reshape(np.linspace(-1,1,6*x_rep),[1,6*x_rep,1])+np.reshape(np.linspace(-1,1,6)*Δx/10,[1,1,6]))**np.reshape(np.arange(k),[k,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d38da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sin=[]\n",
    "dy_sin=[]\n",
    "# for i in range(n):\n",
    "    \n",
    "#     k1 = np.random.uniform(0, 10, [1]).astype('int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "#     k2 = np.random.uniform(0, 10, [1]).astype('int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "#     a  = np.random.uniform(0, 1, [1]) # Amostrando um peso aleatória para ponderar as funções seno\n",
    "#     b  = np.random.uniform(0, 2, [1]) # Amostrando um modificador de amplitude aleatório\n",
    "#     u1 =     a * tf.math.sin(k1*pi*x[1]) # Gerando pontos de acordo com a primeira função seno\n",
    "#     u2 = (1-a) * tf.math.sin(k2*pi*x[1]) # Gerando pontos de acordo com a segunda função seno\n",
    "    \n",
    "#     y_sin.append(b*(u1+u2))\n",
    "    \n",
    "#     u1 =     a * tf.math.sin(k1*pi*x_ref[1]) # Gerando pontos de acordo com a primeira função seno\n",
    "#     u2 = (1-a) * tf.math.sin(k2*pi*x_ref[1]) # Gerando pontos de acordo com a segunda função seno\n",
    "    \n",
    "#     dy_sin.append(b*(u1+u2))\n",
    "\n",
    "#y_sin=np.stack(y_sin,axis=0)\n",
    "y=np.matmul(pesos,x)\n",
    "#y=np.concatenate([y,y_sin],axis=0)\n",
    "\n",
    "#dy_sin=np.stack(dy_sin,axis=0)\n",
    "#dy=np.matmul(np.matmul(pesos,operador_derivada),x+Δx/2)\n",
    "dy=np.matmul(x_ref.T,pesos.T).T\n",
    "#dy=np.concatenate([dy,dy_sin],axis=0)\n",
    "\n",
    "#n=2*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(0):\n",
    "    polis=np.floor(np.random.uniform(size=[n,2],low=0,high=y.shape[0]))\n",
    "    y0=y[polis[:,0].astype('int32')]\n",
    "    y1=y[polis[:,1].astype('int32')]\n",
    "    dy0=dy[polis[:,0].astype('int32')]\n",
    "    dy1=dy[polis[:,1].astype('int32')]\n",
    "    position=np.floor(np.random.uniform(size=[n],low=0,high=y.shape[1])).astype('int32')\n",
    "    probs=np.random.uniform(size=[n])\n",
    "    \n",
    "    for i,j,k in zip(range(n),position,probs):\n",
    "        y0[i,j:]=0\n",
    "        y1[i,:j]=0\n",
    "        dy0[i,(j+1):]=0\n",
    "        dy1[i,:j]=0\n",
    "        \n",
    "        if k>0.75:\n",
    "            dy1[i,j]=0\n",
    "        elif k>0.65:\n",
    "            dy1[i,j,:-1]=0\n",
    "            dy0[i,j,-1:]=0\n",
    "        elif k>0.55:\n",
    "            dy1[i,j,:-2]=0\n",
    "            dy0[i,j,-2:]=0\n",
    "        elif k>0.45:\n",
    "            dy1[i,j,:-3]=0\n",
    "            dy0[i,j,-3:]=0\n",
    "        elif k>0.35:\n",
    "            dy1[i,j,:-4]=0\n",
    "            dy0[i,j,-4:]=0\n",
    "        elif k>0.25:\n",
    "            dy1[i,j,:-5]=0\n",
    "            dy0[i,j,-5:]=0\n",
    "        else:\n",
    "            dy0[i,j]=0\n",
    "    y=y0+y1\n",
    "    dy=dy0+dy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22661301",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δx=Δx/10\n",
    "dy=np.stack(list(map(WENO_Z_ref,np.transpose(dy,[1,0,2]))),axis=0)\n",
    "dy=np.transpose(dy,[1,0,2])\n",
    "Δx=10*Δx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.floor(np.random.uniform(size=[10],low=0,high=n)).astype('int32')\n",
    "\n",
    "plt.figure(figsize=(6.4*5,6.4*2))\n",
    "for i,j in zip(range(10),index):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(y[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4*5,6.4*2))\n",
    "for i,j in zip(range(10),index):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.plot(dy[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate(np.split(y,20,axis=1),axis=0)\n",
    "dy = dy[:,np.arange(2,120,6)]\n",
    "dy = np.concatenate(np.split(dy,20,axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = np.arange(y.shape[0])\n",
    "np.random.shuffle(indice)\n",
    "data_x = y.astype('float64')[indice]\n",
    "data_y = dy.astype('float64')[indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados de treino\n",
    "train_x = data_x[:-20000]\n",
    "train_y = data_y[:-20000]\n",
    "\n",
    "# Conjunto de dados de validação\n",
    "test_x = data_x[-20000:]\n",
    "test_y = data_y[-20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o input da rede e o otimizador de treino\n",
    "input_x   = keras.layers.Input([6], dtype='float64')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10**-3, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "# Criando uma camada de Burgers que integra o WENO à rede neural\n",
    "final_layer = Burguers_layer()\n",
    "\n",
    "class MES_OF(tf.keras.losses.Loss):\n",
    "    \"\"\"Criando uma função de custo cuja superclasse é a de funções de\n",
    "    custo do keras\"\"\"\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Função que avalia o custo dado um valor de referência e um valor previsto\n",
    "        --------------------------------------------------------------------------\n",
    "        y_true (tensor): valor de referência\n",
    "        y_pred (tensor): valor predito\n",
    "        --------------------------------------------------------------------------\n",
    "        loss   (tensor): custo associado\n",
    "        --------------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, y_pred.dtype) # Convertendo os tipos para evitar conflitos\n",
    "        y_min  = tf.math.reduce_min(y_true,axis=1,keepdims=True)\n",
    "        y_max  = tf.math.reduce_max(y_true,axis=1,keepdims=True)\n",
    "        \n",
    "        loss = tf.reduce_mean(\n",
    "            tf.math.square(y_pred - y_true), axis=-1) + \\\n",
    "            tf.reduce_sum(\n",
    "                tf.where(y_pred > y_max, y_pred - y_max,  0) + \\\n",
    "                tf.where(y_pred < y_min, y_min  - y_pred, 0),    \n",
    "            axis=-1)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "# Criando a rede neural\n",
    "Network = keras.Model(input_x, final_layer(input_x))\n",
    "# Configurando a função de perda e o otimizador\n",
    "Network.compile(loss='MSE', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "# Carregando os pesos da rede neural treinados\n",
    "#Network.load_weights('Modelo artigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando a rede neural\n",
    "Network.fit(\n",
    "    train_x                           , # Dados de treino\n",
    "    train_y                           , # Dados de treino\n",
    "    validation_data = (test_x, test_y), # Dados de validação\n",
    "    batch_size      = 1024             , # Tamanho do batch\n",
    "    epochs          = 100             , # Número de epochs\n",
    "    steps_per_epoch = 300             , # Número de batchs por epoch\n",
    "    shuffle         = True              # Aleatorização dos batchs\n",
    ")\n",
    "\n",
    "# Batch: pacote de dados utilizados antes de uma atualização dos pesos da rede\n",
    "# Epoch: rodada de treino da rede neural, em geral percorre todo o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4af5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os pesos treinados\n",
    "Network.save_weights('Modelo Rede para derivada - polinomios grau 4 continuo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5deb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os pesos treinados\n",
    "Network.load_weights('Modelo Rede para derivada - ABS - polinomios + senos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b834f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "\n",
    "Δx = 1/(20*6)                                 # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-2, -1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "\n",
    "# Condição inicial do artigo do WENO-Z\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Função definida no artigo\n",
    "f_test = lambda x: -(-tf.math.sin(np.pi*x) - 0.5 * x**3 + \\\n",
    "    tf.where(x < 0, tf.constant(0.0, dtype=float_pres), tf.constant(1.0, dtype=float_pres)))\n",
    "\n",
    "full_U=f_test(x)\n",
    "full_U=np.stack(np.split(full_U,20,axis=0),axis=0)\n",
    "\n",
    "net_u   = WENO_Z_ref(full_U)             # Previsão com o WENO-Z modificado pela rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ae223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "\n",
    "Δx = (1/(20*6))/2                              # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-2, -1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "\n",
    "# Condição inicial do artigo do WENO-Z\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Função definida no artigo\n",
    "f_test = lambda x: -(-tf.math.sin(np.pi*x) - 0.5 * x**3 + \\\n",
    "    tf.where(x < 0, tf.constant(0.0, dtype=float_pres), tf.constant(1.0, dtype=float_pres)))\n",
    "\n",
    "full_U=f_test(x)\n",
    "full_U=np.stack(np.split(full_U,20*2,axis=0),axis=0)\n",
    "\n",
    "debug_u   = WENO_Z_ref(full_U)[np.arange(100)*2]             # Previsão com o WENO-Z modificado pela rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "\n",
    "Δx = (1/(20*6))/4                               # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-2, -1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "\n",
    "# Condição inicial do artigo do WENO-Z\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Função definida no artigo\n",
    "f_test = lambda x: -(-tf.math.sin(np.pi*x) - 0.5 * x**3 + \\\n",
    "    tf.where(x < 0, tf.constant(0.0, dtype=float_pres), tf.constant(1.0, dtype=float_pres)))\n",
    "\n",
    "full_U=f_test(x)\n",
    "full_U=np.stack(np.split(full_U,20,axis=0),axis=0)\n",
    "\n",
    "ref_full   = WENO_Z_ref(full_U)[np.arange(100)*4]             # Previsão com o WENO-Z modificado pela rede neural\n",
    "\n",
    "# Armazenando ambos os erros de previsão\n",
    "error = tf.stack([tf.squeeze(net_u)-tf.squeeze(ref_full),tf.squeeze(tf.squeeze(debug_u)-tf.squeeze(ref_full))],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67607954",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando média dos erros de acordo com a norma L2, L1 ou L-inf\n",
    "\n",
    "# Norma L2:\n",
    "#--------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_mean(error**2, axis=1)**0.5\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L2:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())\n",
    "print('\\n')\n",
    "\n",
    "# Norma L1:\n",
    "#--------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_mean(tf.abs(error), axis=1)\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L1:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())\n",
    "print('\\n')\n",
    "\n",
    "# Noma L-inf:\n",
    "#-------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_max(tf.abs(error), axis=1)\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L-inf:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # Ornamento que transforma a função em uma função do tensorflow\n",
    "def Burgers(u, t_final, Δx, CFL, fronteira, network=Null_net.Network):\n",
    "    \"\"\"\n",
    "    Função que recebe um tensor u contendo os valores de uma determinada função e retorna os \n",
    "    valores após Δt unidades de tempo estimados de acordo com a equação de Burgers\n",
    "    -------------------------------------------------------------------------------------------\n",
    "    u           (tensor): valores da condição inicial da função\n",
    "    t_final      (float): unidades de tempo a serem avançadas\n",
    "    Δx           (float): distância espacial dos pontos na malha utilizada\n",
    "    CFL          (float): constante utilizada para determinar o tamanho da malha temporal\n",
    "    fronteira (function): função que determina o comportamento do algoritmo na fronteira\n",
    "    network   (function): função que computa o valor de saída da rede neural a partir do valor \n",
    "                          de entrada\n",
    "    -------------------------------------------------------------------------------------------\n",
    "    u           (tensor): valores da função após Δt unidades de tempo\n",
    "    -------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    t = tf.math.reduce_max(tf.abs(u), axis=1, keepdims=True)*0 # Instante de tempo incial para a computação\n",
    "\n",
    "    while tf.math.reduce_any(t < t_final):\n",
    "        Λ  = tf.math.reduce_max(tf.abs(u), axis=1, keepdims=True)\n",
    "\n",
    "        # Obtendo o valor de Δt a partir de CFL\n",
    "        Δt = Δx*CFL/Λ  \n",
    "        u=Burgers_step(u,Δx,CFL,t,t_final, fronteira, network)\n",
    "        t  = t + Δt # Avançando no tempo\n",
    "    return u\n",
    "\n",
    "def Burgers_step(u,Δx,CFL,t,t_final, fronteira, network):\n",
    "    Λ  = tf.math.reduce_max(tf.abs(u), axis=1, keepdims=True)\n",
    "    Δt = Δx*CFL/Λ  \n",
    "    # Caso o passo temporal utrapasse o valor de t_final então o \n",
    "    # tamanho do passo se torna o tempo que falta para se obter o \n",
    "    # t_final\n",
    "    Δt = tf.where(t + Δt > t_final, t_final - t, Δt)\n",
    "\n",
    "    # SSP Runge-Kutta 3,3\n",
    "    u1 = u - Δt*DerivadaEspacial(u, Δx, fronteira, network)\n",
    "    u2 = (3*u + u1 - Δt*DerivadaEspacial(u1, Δx, fronteira, network)) / 4.0\n",
    "    u  = (u + 2*u2 - 2*Δt*DerivadaEspacial(u2, Δx, fronteira, network)) / 3.0\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec03e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o ajuste do WENO-Z com a modificação da rede neural\n",
    "\n",
    "Δx = 0.04                                  # Distância espacial dos pontos na malha utilizada\n",
    "x  = tf.range(-2, 2, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "\n",
    "# Gerando uma condição inicial aleatória\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# k1 = tf.random.uniform([1], 0, 20, dtype='int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "# k1 = tf.cast(k1, dtype=float_pres)                  # Mudando o tipo do tensor\n",
    "# k2 = tf.random.uniform([1], 0, 20, dtype='int32')   # Amostrando uma frequência aleatória para a função seno\n",
    "# k2 = tf.cast(k2, dtype=float_pres)                  # Mudando o tipo do tensor\n",
    "# a  = tf.random.uniform([1], 0, 1, dtype=float_pres) # Amostrando um peso aleatória para ponderar as funções seno\n",
    "# b  = tf.random.uniform([1], 0, 2, dtype=float_pres) # Amostrando um modificador de amplitude aleatório\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Fixando a condição inicial\n",
    "#-----------------------------------------------\n",
    "k1 = 1.0 # Frequência para a função seno\n",
    "k2 = 2.0 # Frequência para a função seno\n",
    "a  = 0.5 # Peso para ponderar as funções seno\n",
    "b  = 0.5 # Modificador de amplitude\n",
    "#-----------------------------------------------\n",
    "\n",
    "\n",
    "u1 =     a * tf.expand_dims(tf.math.sin(k1*pi*x),axis=1) # Gerando pontos de acordo com a primeira função seno\n",
    "u2 = (1-a) * tf.expand_dims(tf.math.sin(k2*pi*x),axis=1) # Gerando pontos de acordo com a segunda função seno\n",
    "\n",
    "u = b*(u1+u2)                 # Obtendo a condição inicial a partir das funções senos\n",
    "u = tf.expand_dims(u, axis=0) # Acrescentando uma dimensão\n",
    "\n",
    "CFL = 0.5                          # Constante utilizada para determinar o tamanho da malha temporal\n",
    "Δt  = 0.01                         # Δt entre cada frame de animação\n",
    "T   = tf.range(0.0, 2.0, Δt)       # Frames da animação\n",
    "T   = tf.cast(T, dtype=float_pres) # Mudando o tipo do tensor\n",
    "\n",
    "t = 0.0 # Instante de tempo inicial\n",
    "\n",
    "\n",
    "# Gerando os gráficos a partir de funções do matplotlib\n",
    "\n",
    "fig = plt.figure(1, constrained_layout=True,figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1);\n",
    "ax.set_ylim(-2, 2);\n",
    "#ax.set_xlim(0,1);\n",
    "line=ax.plot(x,tf.squeeze(u))\n",
    "hfig = display(fig, display_id=True)\n",
    "Δt_list=tf.zeros([0],dtype=float_pres)\n",
    "\n",
    "\n",
    "while t < T[-1]:\n",
    "    \n",
    "    # Executando o WENO-Z modificado pela rede neural\n",
    "    u = Burgers(u, tf.constant(Δt,dtype='float64'), tf.constant(Δx,dtype='float64'), tf.constant(CFL,dtype='float64'), FronteiraPeriodica, network=final_layer.network_graph) \n",
    "    \n",
    "    # Removendo dimensões desnecessárias\n",
    "    squeezed_u=tf.squeeze(u)\n",
    "    \n",
    "    # Avançando no tempo\n",
    "    t += Δt\n",
    "\n",
    "    # Exibindo graficamente os valores obtidos\n",
    "    line[0].set_ydata(squeezed_u.numpy())\n",
    "    fig.canvas.draw()\n",
    "    hfig.update(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9032f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δx_ref = 0.01\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "def df(x):\n",
    "    return np.pi*np.cos(np.pi*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b556b19c-0be1-4817-8197-7e66456cb545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "Δx1 = Δx_ref\n",
    "x1  = np.arange(-1, 1, Δx1)\n",
    "u1  = f(x1)\n",
    "du1 = df(x1)\n",
    "\n",
    "print(u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1f24bfcd-645f-41ad-a631-8de3af8926c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "Δx2 = Δx_ref/2\n",
    "x2  = np.arange(-1, 1, Δx2)\n",
    "u2  = f(x2)\n",
    "du2 = df(x2)\n",
    "\n",
    "print(u2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a538c57c-9984-42f7-a3d8-fad27dc23591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.71939889516899\n"
     ]
    }
   ],
   "source": [
    "# Gerando os gráficos a partir de funções do matplotlib\n",
    "\n",
    "print(np.sum(abs(WENO_Z_ref(u1, Δx1) - df(x1)))/np.sum(abs(WENO_Z_ref(u2, Δx2) - df(x2))))\n",
    "\n",
    "# print(np.mean(abs(WENO_Z_ref(u1, Δx1) - df(x1 + Δx1/2)))/np.mean(abs(WENO_Z_ref(u2, Δx2) - df(x2 + Δx2/2))))\n",
    "\n",
    "# fig = plt.figure(1, constrained_layout=True,figsize=(6,6))\n",
    "# ax  = fig.add_subplot(1,1,1);\n",
    "# # ax.set_ylim(-2, 2);\n",
    "# # ax.set_xlim(0,1);\n",
    "# line = ax.plot(x1, WENO_Z_ref(u1, Δx1) - du1)\n",
    "# # line = ax.plot(x1, du1)\n",
    "# line = ax.plot(x2, WENO_Z_ref(u2, Δx2) - du2)\n",
    "# # line = ax.plot(x2, du2)\n",
    "# hfig = display(fig, display_id=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1ee36a1c-f0d9-440b-a597-2610e0ff8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WENO_Z_ref(u, Δx):\n",
    "    \n",
    "    ɛ = 10.0**(-40)\n",
    "    \n",
    "    u = np.concatenate([u[-3:], u, u[:3]])\n",
    "    \n",
    "    u_full = np.zeros([u.shape[0]-5, 6])\n",
    "    \n",
    "    for i in np.arange(u.shape[0]-5):\n",
    "        u_full[i,:] = u[i:(i+6)]\n",
    "    \n",
    "    f_plus  = u_full[:,:-1] / 2\n",
    "    f_minus = u_full[:,1:]  / 2\n",
    "    f_minus = np.flip(f_minus, axis = 1)\n",
    "    \n",
    "    # Calcula os indicadores de suavidade locais\n",
    "    u = stack_op*f_plus\n",
    "    \n",
    "    β = np.sum(u * (u @ A[:,0]), axis=-1)\n",
    "    β = np.transpose(β)\n",
    "    \n",
    "    # Calcula o indicador de suavidade global\n",
    "    τ = np.abs(β[:,0:1] - β[:,2:3])\n",
    "    \n",
    "    # Calcula os pesos do WENO-Z\n",
    "    α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "    soma = np.sum(α, axis=-1, keepdims=True)\n",
    "    ω    = α / soma\n",
    "    \n",
    "    # Calcula os fhat em cada subestêncil\n",
    "    fhat = f_plus @ C\n",
    "    \n",
    "    f_half_plus = tf.transpose(tf.math.reduce_sum(ω * fhat, axis=1, keepdims=True))[0,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calcula os indicadores de suavidade locais\n",
    "    u = stack_op*f_plus\n",
    "    \n",
    "    β = np.sum(u * (u @ A[:,0]), axis=-1)\n",
    "    β = np.transpose(β)\n",
    "    \n",
    "    # Calcula o indicador de suavidade global\n",
    "    τ = np.abs(β[:,0:1] - β[:,2:3])\n",
    "    \n",
    "    # Calcula os pesos do WENO-Z\n",
    "    α    = (1 + (τ/(β + ɛ))**2) @ B\n",
    "    soma = np.sum(α, axis=-1, keepdims=True)\n",
    "    ω    = α / soma\n",
    "    \n",
    "    # Calcula os fhat em cada subestêncil\n",
    "    fhat = f_minus @ C\n",
    "    \n",
    "    f_half_minus = tf.transpose(tf.math.reduce_sum(ω * fhat, axis=1, keepdims=True))[0,:]\n",
    "    \n",
    "    Fhat = f_half_plus + f_half_minus\n",
    "    Fhat = (Fhat[1:]-Fhat[:-1])/Δx\n",
    "    \n",
    "    return Fhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
