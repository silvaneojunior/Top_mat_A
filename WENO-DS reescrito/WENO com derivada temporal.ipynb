{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7411a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos que serão utilizados\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dill\n",
    "\n",
    "# Configurando o acesso do tensorflow aos processadores do computador\n",
    "# no caso, está sendo selecionada a primeira placa de vídeo listada\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # Listando as placas de vídeo\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)    # Selecionando a primeira GPU e configurando\n",
    "\n",
    "# Importando os módulos contendo as funções criadas no projeto\n",
    "\n",
    "from aux_func_V3 import *\n",
    "import API_Numpy\n",
    "import API_TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1253c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δx=0.05\n",
    "CFL=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824b9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim, Sim_step, DerivadaEspacial, Get_weights=create_simulation(API_Numpy,burgers_equation,WENO_Z)\n",
    "WENO_Z_ref=lambda u0, Δx:Sim(u0,Δx*CFL, Δx, CFL, FronteiraPeriodica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20885af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets\\\\Dados temporais.bkp','rb') as file:\n",
    "    y,dy=dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e067dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = np.arange(y.shape[0])\n",
    "np.random.shuffle(indice)\n",
    "data_x = y.astype('float64')[indice]\n",
    "data_y = dy.astype('float64')[indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f438047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados de treino\n",
    "train_x = data_x#[:-20000]\n",
    "train_y = data_y#[:-20000]\n",
    "\n",
    "# Conjunto de dados de validação\n",
    "test_x = data_x#[-20000:]\n",
    "test_y = data_y#[-20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8a5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma camada de Burgers que integra o WENO à rede neural\n",
    "Sim_layer = WENO_temporal(Δx, CFL, Δx*CFL, FronteiraPeriodica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30123b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o input da rede e o otimizador de treino\n",
    "input_x   = keras.layers.Input([train_x.shape[1]], dtype='float64')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10**-3, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "# Criando a rede neural\n",
    "Network = keras.Model(input_x, Sim_layer(input_x))\n",
    "# Configurando a função de perda e o otimizador\n",
    "Network.compile(loss=MES_OF(), optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "# Carregando os pesos da rede neural treinados\n",
    "#Network.load_weights('Modelo artigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce807ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.0240e-04 - mean_absolute_error: 5.4030e-04(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "300/300 [==============================] - 586s 2s/step - loss: 1.0240e-04 - mean_absolute_error: 5.4030e-04 - val_loss: 1.0213e-04 - val_mean_absolute_error: 5.4030e-04\n",
      "Epoch 2/100\n",
      "  4/300 [..............................] - ETA: 9:23 - loss: 9.9949e-05 - mean_absolute_error: 5.3855e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-411143ae01d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Treinando a rede neural\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m Network.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_x\u001b[0m                           \u001b[1;33m,\u001b[0m \u001b[1;31m# Dados de treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_y\u001b[0m                           \u001b[1;33m,\u001b[0m \u001b[1;31m# Dados de treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Dados de validação\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Treinando a rede neural\n",
    "Network.fit(\n",
    "    train_x                           , # Dados de treino\n",
    "    train_y                           , # Dados de treino\n",
    "    validation_data = (test_x, test_y), # Dados de validação\n",
    "    batch_size      = 1024            , # Tamanho do batch\n",
    "    epochs          = 100             , # Número de epochs\n",
    "    steps_per_epoch = 300             , # Número de batchs por epoch\n",
    "    shuffle         = True              # Aleatorização dos batchs\n",
    ")\n",
    "\n",
    "# Batch: pacote de dados utilizados antes de uma atualização dos pesos da rede\n",
    "# Epoch: rodada de treino da rede neural, em geral percorre todo o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f20e95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os pesos treinados\n",
    "Network.save_weights('Modelos treinados\\\\Modelo Rede temporal - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cfebda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x28a9cf454f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando os pesos treinados\n",
    "Network.load_weights('Modelos treinados\\\\Modelo Rede temporal - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15843a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o input da rede e o otimizador de treino\n",
    "input_x   = keras.layers.Input([200], dtype='float64')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10**-3, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "# Criando a rede neural\n",
    "Network = keras.Model(input_x, Sim_layer(input_x))\n",
    "# Configurando a função de perda e o otimizador\n",
    "Network.compile(loss='MSE', optimizer=optimizer, metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b4a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "Δx_ref = 0.01\n",
    "Δx = Δx_ref                                # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-1, 1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "\n",
    "# Condição inicial do artigo do WENO-Z\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Função definida no artigo\n",
    "f_test = lambda x: -(-tf.math.sin(np.pi*x) - 0.5 * x**3 + \\\n",
    "    tf.where(x < 0, tf.constant(0.0, dtype=float_pres), tf.constant(1.0, dtype=float_pres)))\n",
    "\n",
    "full_U=tf.expand_dims(f_test(x),axis=0)\n",
    "\n",
    "net_u   = Network(full_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4883dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "\n",
    "k=1\n",
    "\n",
    "Δx = Δx_ref/k                              # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-1, 1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "# Condição inicial do artigo do WENO-Z\n",
    "\n",
    "full_U=tf.expand_dims(f_test(x),axis=0)\n",
    "\n",
    "debug_u   = WENO_Z_ref(full_U,Δx)         # Previsão com o WENO-Z modificado pela rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1cece48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculando os erros de previsão utilizando o WENO-Z em uma malha mais fina \n",
    "# como solução de referência e depois calculando o WENO-Z e o WENO-Z com a \n",
    "# modificação da rede neural numa malha mais grossa\n",
    "\n",
    "k=2\n",
    "\n",
    "Δx = Δx_ref/k                               # Distância espacial dos pontos na malha mais grossa utilizada\n",
    "x  = tf.range(-1, 1, Δx, dtype=float_pres) # Gerando a malha de pontos no espaço unidimensional\n",
    "                             # Distância espacial dos pontos na malha utilizada\n",
    "\n",
    "full_U=tf.expand_dims(f_test(x),axis=0)\n",
    "\n",
    "ref_full   = tf.gather(WENO_Z_ref(full_U,Δx),np.arange(net_u.shape[-1])*k,axis=-1)             # Previsão com o WENO-Z modificado pela rede neural\n",
    "\n",
    "# Armazenando ambos os erros de previsão\n",
    "error = tf.stack([net_u-ref_full,debug_u-ref_full],axis=0)\n",
    "error = tf.squeeze(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "827c8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2:\n",
      "[0.2778602  0.27500402]\n",
      "1.010385958155875\n",
      "\n",
      "\n",
      "L1:\n",
      "[0.70187221 0.69486957]\n",
      "1.010077631954841\n",
      "\n",
      "\n",
      "L-inf:\n",
      "[0.27491981 0.27217183]\n",
      "1.0100964671514348\n"
     ]
    }
   ],
   "source": [
    "# Calculando média dos erros de acordo com a norma L2, L1 ou L-inf\n",
    "\n",
    "# Norma L2:\n",
    "#--------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_sum(error**2, axis=-1)**0.5\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L2:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())\n",
    "print('\\n')\n",
    "\n",
    "# Norma L1:\n",
    "#--------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_sum(tf.abs(error), axis=-1)\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L1:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())\n",
    "print('\\n')\n",
    "\n",
    "# Noma L-inf:\n",
    "#-------------------------------------------------------------------------------------\n",
    "desv_error = tf.math.reduce_max(tf.abs(error), axis=-1)\n",
    "#--------------------------------------------------------------------------------------\n",
    "print('L-inf:')\n",
    "# Erro médio para a rede neural e o WENO-Z (respectivamente)\n",
    "print(desv_error.numpy())\n",
    "# Diferença entre os erros (WENO-Z - rede neural)\n",
    "# print((desv_error[1]-desv_error[0]).numpy())\n",
    "# Razão entre os erros (rede neural/WENO-Z)\n",
    "print((desv_error[0]/desv_error[1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bc578b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim, Sim_step, DerivadaEspacial, Get_weights=create_simulation(API_Numpy,burgers_equation,WENO_Z)\n",
    "WENO_Z_ref=lambda u0, Δx:DerivadaEspacial(u0,Δx, FronteiraPeriodica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135caa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Δx_ref = 0.01\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "def df(x):\n",
    "    return np.pi*np.cos(np.pi*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29397c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n",
      "(None, 201, None)\n",
      "(None, 201, 3)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o input da rede e o otimizador de treino\n",
    "input_x   = keras.layers.Input([200], dtype='float64')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10**-3, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "# Criando a rede neural\n",
    "Network = keras.Model(input_x, Sim_layer(input_x))\n",
    "# Configurando a função de perda e o otimizador\n",
    "Network.compile(loss='MSE', optimizer=optimizer, metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09fb5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 201, 3)\n",
      "(1, 200)\n"
     ]
    }
   ],
   "source": [
    "Δx1 = Δx_ref\n",
    "x1  = np.arange(-1, 1, Δx1)\n",
    "x1  = np.expand_dims(x1,0)\n",
    "u1  = f(x1)\n",
    "du1 = df(x1)\n",
    "y1=Network(u1, Δx1)\n",
    "\n",
    "print(u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a09a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 401, None)\n",
      "(None, 401, 3)\n",
      "(None, 401, None)\n",
      "(None, 401, 3)\n",
      "(None, 401, None)\n",
      "(None, 401, 3)\n",
      "(None, 401, None)\n",
      "(None, 401, 3)\n",
      "(None, 401, None)\n",
      "(None, 401, 3)\n",
      "(None, 401, None)\n",
      "(None, 401, 3)\n"
     ]
    }
   ],
   "source": [
    "# Definindo o input da rede e o otimizador de treino\n",
    "input_x   = keras.layers.Input([400], dtype='float64')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10**-3, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "\n",
    "# Criando a rede neural\n",
    "Network = keras.Model(input_x, Sim_layer(input_x))\n",
    "# Configurando a função de perda e o otimizador\n",
    "Network.compile(loss='MSE', optimizer=optimizer, metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64759e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 401, 3)\n",
      "(1, 400)\n"
     ]
    }
   ],
   "source": [
    "Δx2 = Δx_ref/2\n",
    "x2  = np.arange(-1, 1, Δx2)\n",
    "x2  = np.expand_dims(x2,0)\n",
    "u2  = f(x2)\n",
    "du2 = df(x2)\n",
    "y2=Network(u2, Δx2)\n",
    "\n",
    "print(u2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e28840fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49998893595719707\n"
     ]
    }
   ],
   "source": [
    "# Gerando os gráficos a partir de funções do matplotlib\n",
    "\n",
    "print(np.sum(abs(y1 - du1))/np.sum(abs(y2 - du2)))\n",
    "\n",
    "# print(np.mean(abs(WENO_Z_ref(u1, Δx1) - df(x1 + Δx1/2)))/np.mean(abs(WENO_Z_ref(u2, Δx2) - df(x2 + Δx2/2))))\n",
    "\n",
    "# fig = plt.figure(1, constrained_layout=True,figsize=(6,6))\n",
    "# ax  = fig.add_subplot(1,1,1);\n",
    "# # ax.set_ylim(-2, 2);\n",
    "# # ax.set_xlim(0,1);\n",
    "# line = ax.plot(x1, WENO_Z_ref(u1, Δx1) - du1)\n",
    "# # line = ax.plot(x1, du1)\n",
    "# line = ax.plot(x2, WENO_Z_ref(u2, Δx2) - du2)\n",
    "# # line = ax.plot(x2, du2)\n",
    "# hfig = display(fig, display_id=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
